
<!DOCTYPE html>


<html lang="es" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Hallucination in Artificial Intelligence" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://www.cosmoscalibur.com/en/blog/2025/alucinacion-de-la-inteligencia-artificial/" />
<meta property="og:site_name" content="Cosmoscalibur" />
<meta property="og:description" content="Robots also dream. Yes, and they dream while awake. The hallucination in language models (or artificial intelligences) is inevitable. Not everything generated by an AI can be trusted, and you shoul..." />
<meta property="og:image:width" content="1146" />
<meta property="og:image:height" content="600" />
<meta property="og:image" content="https://www.cosmoscalibur.com/_images/social_previews/summary_en_blog_2025_alucinacion-de-la-inteligencia-artificial_1e3522b0.png" />
<meta property="og:image:alt" content="Robots also dream. Yes, and they dream while awake. The hallucination in language models (or artificial intelligences) is inevitable. Not everything generated by an AI can be trusted, and you shoul..." />
<meta name="description" content="Robots also dream. Yes, and they dream while awake. The hallucination in language models (or artificial intelligences) is inevitable. Not everything generated by an AI can be trusted, and you shoul..." />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:creator" content="@cosmoscalibur" />
<meta name="fediverse:creator" content="@cosmoscalibur@col.social">

    <title>Hallucination in Artificial Intelligence &#8212; Cosmoscalibur</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=a20647df"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/translations.js?v=f85f4cfb"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-4YFQBC69LB"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-4YFQBC69LB');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'en/blog/2025/alucinacion-de-la-inteligencia-artificial';</script>
    <link rel="canonical" href="https://www.cosmoscalibur.com/en/blog/2025/alucinacion-de-la-inteligencia-artificial/" />
    <link rel="icon" href="../../../../_static/cosmoscalibur_favicon.png"/>
    <link rel="index" title="Índice" href="../../../../genindex/" />
    <link rel="search" title="Búsqueda" href="../../../../search/" /> 

<!-- TODO: Revisar como hacer que dependa del despliegue en GitHub Pages para no usar en local -->
<!-- TODO: Usar GitHub Actions para esto -->

<!-- Usado para mostrar publicidad -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0356238418278924"
crossorigin="anonymous"></script>

 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../../blog/atom.xml"
  title="Cosmoscalibur"
/>
  
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Saltar al contenido principal</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Volver arriba</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Advertencia de versión"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Navegación del sitio">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/cosmoscalibur_logo.png" class="logo__image only-light" alt="Cosmoscalibur - Home"/>
    <img src="../../../../_static/cosmoscalibur_logo.png" class="logo__image only-dark pst-js-only" alt="Cosmoscalibur - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../es/me/">
    Edward Villegas
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Búsqueda" aria-label="Búsqueda" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Búsqueda</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Tema" data-bs-title="Tema"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Claro"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Oscuro"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="Sistema"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cosmoscalibur/" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/cosmoscalibur" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
            
          
            
          
          
          
          
          
          
          
          
          
          <a href="https://col.social/@cosmoscalibur" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-mastodon fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Búsqueda" aria-label="Búsqueda" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Búsqueda</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="En esta página">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../es/me/">
    Edward Villegas
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Tema" data-bs-title="Tema"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Claro"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Oscuro"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="Sistema"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cosmoscalibur/" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/cosmoscalibur" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
            
          
            
          
          
          
          
          
          
          
          
          
          <a href="https://col.social/@cosmoscalibur" title="Mastodon" class="nav-link pst-navbar-icon" rel="me" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fab fa-mastodon fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mastodon</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__postcard">
   
  <h2>
     
    <span>2025-02-13</span>
    
  </h2>
  <ul>
    <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
       Autor: 
    </span>
     
    <a href="../../../../blog/author/edward-villegas-pulgarin/">Edward Villegas-Pulgarin</a>
      
  </li>
    
  <li id="ablog-sidebar-item language ablog__language">
    <span>
       Idioma: 
    </span>
     
    <a href="../../../../blog/language/english/">English</a>
      
  </li>
   
  <li id="ablog-sidebar-item category ablog__category">
    <span>
       Categoría: 
    </span>
     
    <a href="../../../../blog/category/technology/">technology</a>
      
  </li>
   
  <li id="ablog-sidebar-item tags ablog__tags">
    <span>
        Etiquetas:  
    </span>
     
    <a href="../../../../blog/tag/language-model/">language model</a>
        
    <a href="../../../../blog/tag/artificial-intelligence/">artificial intelligence</a>
      
  </li>
   
</div>
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__recentposts">
  <h3>
    <a href="../../../../blog/">Entradas recientes</a>
  </h3>
  <ul>
     
    <li>
      <a href="../../../../es/blog/2024/ecosistema-rust-para-la-terminal-linux/">
        2025-04-29 - Ecosistema Rust para la terminal Linux
      </a>
    </li>
    
    <li>
      <a href="../instalar-docker-en-manjaro/">
        2025-04-23 - Install Docker on Manjaro
      </a>
    </li>
    
    <li>
      <a href="../../../../es/blog/2025/instalar-docker-en-manjaro/">
        2025-04-23 - Instalar Docker en Manjaro
      </a>
    </li>
    
    <li>
      <a href="../../../../es/blog/2025/aprendiendo-rust-parte-1/">
        2025-03-31 - Aprendiendo Rust: Parte 1 - Uso básico de cargo, variables y flujos de control
      </a>
    </li>
    
    <li>
      <a href="../../../../es/blog/2025/zed-un-editor-rapido-y-moderno-de-codigo-abierto/">
        2025-03-27 - Zed: un editor rápido y moderno de código abierto
      </a>
    </li>
    
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__archives">
  <h3>
    <a href="../../../../blog/archive/">Archivos</a>
  </h3>
  <ul>
     
    <li>
      <a href="../../../../blog/2025/">2025 (17)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2024/">2024 (35)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2021/">2021 (2)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2020/">2020 (21)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2019/">2019 (9)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2018/">2018 (5)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2017/">2017 (2)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2014/">2014 (1)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2013/">2013 (12)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2012/">2012 (20)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2011/">2011 (30)</a>
    </li>
      
    <li>
      <a href="../../../../blog/2010/">2010 (7)</a>
    </li>
     
  </ul>
</div>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Miga de pan" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../" class="nav-link" aria-label="Inicio">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Hallucination in Artificial Intelligence</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <section class="tex2jax_ignore mathjax_ignore" id="hallucination-in-artificial-intelligence">
<h1>Hallucination in Artificial Intelligence<a class="headerlink" href="#hallucination-in-artificial-intelligence" title="Link to this heading">#</a></h1>
<p>Robots also dream. Yes, and they dream while awake. The hallucination in
language models (or artificial intelligences) is inevitable. Not everything
generated by an AI can be trusted, and you should have appropriate criteria to
judge the information produced. In general, AI is a good assistant, but only
that—its purpose is to assist you, and the final decision must always be yours.
Here I will illustrate why this is important.</p>
<section id="what-is-hallucination-in-artificial-intelligence">
<h2>What Is Hallucination in Artificial Intelligence?<a class="headerlink" href="#what-is-hallucination-in-artificial-intelligence" title="Link to this heading">#</a></h2>
<p>Hallucination refers to the phenomenon where responses generated are coherent
and grammatically correct, yet factually incorrect or nonsensical. In other
words, it involves the generation of false information.</p>
</section>
<section id="types-of-language-model-hallucinations">
<h2>Types of Language Model Hallucinations<a class="headerlink" href="#types-of-language-model-hallucinations" title="Link to this heading">#</a></h2>
<p>Language model (LLM) hallucinations have been characterized:</p>
<ul class="simple">
<li><p>Factual Errors or Contradictions: This type of <strong>factual hallucination</strong>
occurs when the responses can be compared to real information and the response
presents contradictions or falsehoods.</p></li>
<li><p>Fabrication of Facts: This is another type of factual hallucination where the
responses cannot be verified, are nonexistent data, or the answers are
debatable.</p></li>
<li><p>Instruction Inconsistency: This type of faithfulness hallucination occurs when
the instruction or question is deviated or altered.</p></li>
<li><p>Context Inconsistency: This type of faithfulness hallucination happens when
the instruction ignores contextual information.</p></li>
<li><p>Logical Inconsistency: This type of faithfulness hallucination involves
presenting logical contradictions, such as mathematical reasoning errors.</p></li>
</ul>
</section>
<section id="why-do-language-models-hallucinate">
<h2>Why Do Language Models Hallucinate?<a class="headerlink" href="#why-do-language-models-hallucinate" title="Link to this heading">#</a></h2>
<p>There are multiple reasons why language models (LLMs) exhibit hallucinations.
These can include:</p>
<ul class="simple">
<li><p>Outdated Training Data: The models possess a base set of data on which they
are trained and that is limited in time. Therefore, if the model had a
training cutoff in 2022, you cannot expect responses based on subsequent
information. It’s important to be aware of the training data cutoff of the
model you choose.</p></li>
<li><p>Data Bias: Information collection can present biases, and the most common one
we encounter is generated by the language used in the majority of sources. For
example, models like <em>Qwen</em> and <em>Deepseek</em> have a strong bias towards English
and Chinese (more noticeable in <em>deepseek</em> and lighter versions of <em>qwen</em>).</p></li>
<li><p>Misinformation Sources: In general, the sources are not cleaned up, and there
is a high presence of web-extracted data from general sources that may contain
erroneous or false information (even deliberately as an attack to language
models).</p></li>
<li><p>Lack of Data or Truth Source: Not everything we can consult is in the dataset
or simply there is no information. This could be due to copyright limitations
on existing content or limitations of the knowledge itself.</p></li>
<li><p>Ambiguous Questions: The more ambiguous the question, the higher the
probability of hallucination because it is subject to the “interpretation” of
the model. You can consider how if the model will compare similar questions.
Generally, we improve results by increasing the level of specificity in the
query.</p></li>
<li><p>Reasoning Failures: Most models have low reasoning capabilities. LLMs
understand language structure (or mimic it), but there are no causal chains
within the context that represent their words (<em>tokens</em>).</p></li>
<li><p>High Computational Complexity: The higher the computational complexity of a
problem, the more sensitive it is to hallucinations. For example,
combinatorial problems can be highly sensitive.</p></li>
</ul>
</section>
<section id="can-language-model-hallucinations-be-avoided">
<h2>Can Language Model Hallucinations Be Avoided?<a class="headerlink" href="#can-language-model-hallucinations-be-avoided" title="Link to this heading">#</a></h2>
<p>Given all that has been mentioned above, an important question is whether this
problem of hallucinations can be solved. However, the honest and unpalatable
truth is that there will always be some level of hallucination in language
models (and reasoning models), no matter how we try to mitigate it.</p>
<p>The training data set for a model is always a subset or approximation of the
real world, but the very construction of the model is an iterative process that
seeks patterns within its dataset and allows it to converge. This convergence
causes the model to stop short of fully approximating the source of truth and
results in overfitting. In other words, the model is an approximation of the
data used for training, which can lead to inaccuracies or biases.</p>
</section>
<section id="which-model-to-use-to-reduce-hallucinations">
<h2>Which Model to Use to Reduce Hallucinations?<a class="headerlink" href="#which-model-to-use-to-reduce-hallucinations" title="Link to this heading">#</a></h2>
<p>This question is not straightforward, and we cannot rely on standard comparison
tests of the models either, as these tests are standardized. This is an
important criticism because standardized tests gradually become part of the
model training process. Therefore, the best you can do is to
<a class="reference internal" href="../instala-tu-asistente-local-de-ia/"><span class="std std-doc">test different models</span></a>.
Build a set of questions related to your daily life, work, and areas of interest
where you have knowledge and can validate the certainty and quality of the
responses. And from there, choose.</p>
<p>Given that one source of hallucination is data bias, this is important because
standardized tests are in English. Therefore, a good model might not be the best
choice for you if you don’t dominate English, or if your field has limited
public data—perhaps the best model isn’t the one with more information relevant
to your interests.</p>
</section>
<section id="id1">
<h2>Which Model to Use to Reduce Hallucinations?<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>In general, “ultralight” models are not a good idea (those with fewer than 3
billion parameters are a constant source of hallucinations), as a smaller number
of parameters implies a loss of data, connections between them, and semantic
language structure.</p>
<p>A good starting point is <em>qwen2.5:3b</em> or <em>llama3.2:3b</em> if you do not have a GPU.
These models are decent but exhibit significant regional context bias (in my
case, Colombia) and Spanish bias. However, they have a very good context for
code-related tasks or English queries. I tested them on a machine without a GPU
with 16 GB of RAM. However, if you have a GPU, my recommendation is to use
<em>qwen2.5:7b</em> or <em>qwen2.5:14b</em>. Definitely do not recommend using <em>Phi</em> (it has
significant language biases) or any variant of <em>Deepseek</em> (<em>deepseek-r1</em>
included), which are distilled versions of <em>Qwen2</em>, <em>Qwen2.5</em>, and <em>Llama3.1</em>,
with reduced precision, continuous loss of context, and mixed-language issues.</p>
<p>Math-specialized models disappointed me, but the issue might be bias when asking
in Spanish. For mathematical purposes in Spanish, I recommend using the general
versions of <em>qwen2.5:7b</em> and <em>qwen2.5:14b</em>.</p>
<p>In code-specialized versions, my recommendation holds true for the family of
<em>qwen2.5</em>, with its variant <em>qwen2.5-coder</em>. The version <em>qwen2.5-coder:3b</em> is
useful if you do not have a GPU; however, <em>qwen2.5-coder:7b</em> on a GPU provides a
good balance without excessive resource consumption. It’s important to use the
code-specialized versions because they provide the appropriate integration for
code autocompletion with code editors and more precise responses when asking
about programming topics. A curiosity about <em>qwen2.5-coder:7b</em>, it is used as
the base model for the
<a class="reference external" href="https://zed.dev/blog/edit-prediction"><em>zeta</em> of <strong class="program">zed</strong></a>.</p>
<p>If you have a better machine, you can try larger models. In my case with an RTX
2060 GPU and 16 GB of RAM, I hit the limit with <em>14b</em> models. But keep in mind
that for your use case, increasing the model size might not be necessary. For
example, although I can run <em>qwen2.5:14</em>, I do not see additional benefits
compared to <em>qwen2.5:7b</em> in my usage scenario.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.iguazio.com/glossary/llm-hallucination/">What are LLM Hallucinations?</a>.</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2311.05232v2">A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions</a>.</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2409.05746v1">LLMs Will Always Hallucinate, and We Need to Live With This</a>.</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2401.11817">Hallucination is Inevitable: An Innate Limitation of Large Language Models</a>.</p></li>
</ul>
</section>
</section>

<div class="section ablog__blog_comments">
     
<div class="section ablog__prev-next">
  <span class="ablog__prev">
      Anterior:
    
    <a href="../../../../es/blog/2025/alucinacion-de-la-inteligencia-artificial/">
      
      <span>Alucinación de la inteligencia artificial</span>
    </a>
    
  </span>
  <span class="ablog__spacer">&nbsp;</span>
  <span class="ablog__next">
      Siguiente: 
    <a href="../../../../es/blog/2025/zed-un-editor-rapido-y-moderno-de-codigo-abierto/">
      <span>Zed: un editor rápido y moderno de código abierto</span>
      
    </a>
    
  </span>
</div>
  
</div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> En esta página
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-hallucination-in-artificial-intelligence">What Is Hallucination in Artificial Intelligence?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-language-model-hallucinations">Types of Language Model Hallucinations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-do-language-models-hallucinate">Why Do Language Models Hallucinate?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#can-language-model-hallucinations-be-avoided">Can Language Model Hallucinations Be Avoided?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#which-model-to-use-to-reduce-hallucinations">Which Model to Use to Reduce Hallucinations?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Which Model to Use to Reduce Hallucinations?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>Esta página</h3>
    <ul class="this-page-menu">
      <li><a href="../../../../_sources/en/blog/2025/alucinacion-de-la-inteligencia-artificial.md.txt"
            rel="nofollow">Mostrar el código</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, Edward Villegas-Pulgarin.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Creado usando <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Construido con el <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html"> Tema PyData Sphinx </a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>